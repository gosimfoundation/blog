---
title: 对话 LAION 科研负责人 Jenia Jitsev | Open AGI Forum
date: 24 June 2025
description: '一场源于“绝望”的科学复兴运动 '
image: /blogs-img/blog13-Jenia-Jitsev.jpg
alt: First Post
ogimage: /blogs-img/blog13-Jenia-Jitsev.jpg
tags: ['gosim', 'open-source', 'grassroots']
published: true
---

*作者 & 采访 | 王启隆 Eric Wang*  
*出品 | GOSIM 开源创新汇*  

2021 年 1 月，当 OpenAI 的 DALL-E 模型用一串文本便能生成“精彩绝伦的图像”时，整个科技界为之震动。

然而，在这片赞叹声中，一种更复杂的情绪正在一群科学家、工程师和爱好者心中悄然发酵——那是一种混杂着敬畏与深刻挫败感的“绝望”。

这种绝望，源于一个日益尖锐的矛盾：人工智能领域最前沿、最具革命性的成果，正被越来越多地锁在少数科技巨头的“黑箱”之中。模型不开源，数据集不公开，研究过程无法复现。对于视“可复现性”为基石的科学界而言，这无异于前路被巨石阻断。你如何去研究一个你甚至无法独立验证的现象？

火花，在德国一间普通的高中课堂之外被点燃。Christoph Schuhmann，一位物理与计算机科学教师，在读完 DALL-E 的论文后，内心深受震撼。一个强烈的念头在他心中萌发：我们必须能够复现这样的模型！他立刻意识到，首要的、也是最大的障碍，是那个外界无从知晓的海量训练数据集。

在 Elute AI 服务器，一个 AI 爱好者的在线社群里，Schuhmann 提出了一个看似简单却极具开创性的想法：我们或许可以从 Common Crawl（一个巨大的公开网页存档）中，抓取那些附带了描述性文本的图片链接，以此来构建我们自己的数据集。起初，响应者寥寥，一些人因各种原因很快分心。但他没有放弃。

不久，一位名叫 Theo Coombes 的程序员成为第一个响应者，两人共同发起了“在家爬虫”（Crawling at Home）计划。这标志着 LAION 从一个人的执着，转变为一项协作的努力。2021 年 3 月，一个独立的 Discord 服务器应运而生，并迅速成为这个新生组织的“神经中枢”。

这个服务器像一块投入水中的磁石，迅速吸引了来自世界各地的“铁屑”——一个由科学家、开发者、工程师和普通爱好者组成的，堪称“梦之队”的多元化网络开始形成：

* Jenia Jitsev 博士，我们本次对话的主角，尤利希超级计算中心（JSC）的高级研究员，手握着将这场草根运动推向工业级规模的关键钥匙——超级计算机的算力。

* Richard Vencu，一位拥有近三十年行业经验的资深工程师，他负责构建和维护 LAION 赖以生存的技术基础设施。此前，我们在 Open AGI Forum 也和他进行过对话。

* Robert Kaczmarczyk，一位医生和流行病学研究者，他为项目注入了宝贵的伦理视角和社会责任感。

* 还有 Mehdi Cherti、Jan Ebert 这样的深度学习专家，以及像 Aarush Katta 一样充满热情的程序员……

这些背景迥异的个体，因一个共同的信念而汇聚。他们将这个组织命名为 LAION（Large-scale Artificial Intelligence Open Network），并立下了核心信条：100% 非营利，100% 免费。其使命被清晰地定义为“解放机器学习研究”，旨在通过提供开放的数据集、工具和模型，来对抗人工智能发展中日益集权化和不透明的趋势。

当 Christoph Schuhmann 的“在家爬虫”计划与 Jenia Jitsev 在尤利希的超级计算机相遇时，一场真正的化学反应发生了。志愿者的热情与世界顶级的计算资源相结合，让复现甚至超越“黑箱”中的模型成为了可能。

不久，来自斯坦福大学的 Ludwig Schmidt 教授也加入了进来，带来了他对 OpenCLIP 的研究成果和顶尖学府的学术严谨性，为 LAION 的产出质量提供了关键
背书。

LAION 的诞生，并非仅仅出于技术上的好奇，而是对当时行业趋势的一种直接的、有意识的意识形态回应。它代表了一种深思熟虑的选择，旨在开辟一条截然不同的道路。

在 GOSIM AI Paris 2025 大会的法国巴黎现场，我们与这场“科学复兴运动”的科学架构师 Jenia Jitsev 博士进行了深入对话。他的讲述，不仅为我们揭开了 LAION 的起源、挑战，以及他们如何通过“爱丽丝梦游仙境”等研究，持续为这个高歌猛进的行业进行冷静的“压力测试”，更展现了一个由分布式人才组成的开放心灵网络，是如何改变科学探索的游戏规则的。


## LAION 的诞生源于对“黑箱”的绝望

**Eric Wang: 欢迎您，Jenia。这次来参加 GOSIM 巴黎 AI 大会，感觉现场的氛围怎么样？**

**Jenia Jitsev**: 感觉非常好，很高兴见到了许多老朋友，比如 Hugging Face 和 LightArch 社区的伙伴们。还碰到了 Llama Factory 项目的朋友，我们自己的 OpenThoughts 项目就用他们的工具来做微调，研究推理和追踪数据 (reasoning traces)。我们还和斯坦福、伯克利的朋友们紧密合作，一起推出了 OpenThinker 模型，有 320 亿和 70 亿两种参数规模。

所以你能看到，整个开源社区的合作氛围特别好，大家都在做对彼此都有益的事情。我希望能找到更好的方法来深化协作。毕竟，能互相帮助、避免重复造轮子肯定是好事，但这背后离不开高效的组织和管理。

**Eric Wang: 我本来想请您先做个自我介绍，但发现您的履历上有很多身份。为了让观众更了解您，能解释一下这些不同的角色和组织，在您的工作中是如何串联起来的吗？**

**Jenia Jitsev**: 当然。我和 Mehdi Cherti、Mariana Nijurina 都是非营利组织 LAION 的核心研究员，但我们真正的“雇主”或者说资助机构，是亥姆霍兹联合会（Helmholtz Association），这是德国一个大型的科研组织。

你可以把亥姆霍兹联合会和马克斯·普朗克学会（Max Planck organization）看作德国科研的两大支柱。区别在于，亥姆霍兹更侧重于运维那些需要大量资金和人力才能维持的大型、昂贵的科研设备，这其中就包括超级计算机。

我们所在的研究所，就隶属于亥姆霍兹，它叫于利希超级计算中心（Jülich Supercomputing Centre），在科隆附近。这个中心从上世纪 80 年代起，就有托管和运维超级计算机的悠久传统。我的研究实验室就诞生于此，也一直在那里运作。我们的研究经费来自亥姆霍兹联合会，也就是最终来自德国政府，所以我们是一个公共研究机构。

而另一条线，就是我们的非营利研究组织 LAION。它在 2021 年名义上于汉堡成立，但我说“名义上”，是因为我们在汉堡并没有实体办公室。LAION 是一个去中心化的组织，由一群强大的实验室构成，大家为了共同的目标走到一起。这些目标基本上都围绕着开放的基础模型，以及创建这些模型所必需的数据集。

所以，你可以把 LAION 理解成一个“联合体”，它把各个独立研究机构里的实验室连接了起来。比如，我们在于利希的实验室，斯坦福的路德维希·施密特（Ludwig Schmidt）和他强大的实验室，还有东京工业大学的横田良（Ryo Yokota）——他也是 LAION 的资深研究员——和他的学生中村太一（Taishi Nakamura）的实验室。从这个意义上说，LAION 是一个由强大实验室组成的网络，而我们自己的研究所，则为这个网络提供了一个重要的“托管”和支持。大概就是这样一种关系。

**Eric Wang: 我们之前和 LAION 的另一位创始人 Richard Vencu 聊过，听他讲了 LAION 的起源故事。那么从您的视角来看，这个故事又是怎样的？**

**Jenia Jitsev**: 哈哈，这倒有意思了，看看我们的说法能不能对得上。要是对不上，那可就有趣了。

不过说真的，这故事确实有点像电影。我不是自夸，但整个过程充满了冒险色彩，现在回想起来都觉得回味无穷。LAION 的核心成员们加入的动机各不相同，但驱动我们的，是一种相似的“绝望感”——我们眼睁睁看着那些强大的模型被创造出来，它们明明具备极高的研究价值，但我们却无法研究，因为它们被锁在“黑箱”里，外界根本无法复现。

但每个人的具体动机又不太一样。从我们实验室的角度来说，故事确实起源于一次内部的文献研讨会。当时我的同事 Mehdi Cherti 正在分享 OpenAI 关于 DALL·E 1 代的论文。

那是 2021 年，当时有两篇论文影响巨大，我记得都和我们心目中永远的英雄 Alec Radford 有关：一篇是 CLIP 论文，另一篇就是 DALL·E。CLIP 在某种程度上更开放一些，至少他们发布了模型权重。但总的来说，整个研究还是无法复现的，数据集没有公开。至于 DALL·E，那就更彻底了，我们连模型都拿不到。

在那次研讨会上，我们都意识到，必须把这类成果作为核心的机器学习问题来研究，因为它就是“可迁移学习”的源头，而这正是机器学习的圣杯。我们必须搞清楚，它到底为什么能行。

于是我们立刻行动起来，上网搜索有谁在尝试用开源的方式复现它。说来也巧，就在研讨会进行中，我们用谷歌一搜，就发现了一些线索，有人已经建了一个 Discord 服务器，好像就叫“DALL·E 复现服务器”。

我们还找到了 LucidRains，也就是 Phil Wang，他有个非常了不起的习惯，就是把所有重要的研究成果都亲手复现一遍。我们找到了他那个 DALL·E 复现项目的 GitHub 仓库，就在上面提了个 issue（可以理解为发起了一个公开讨论），大意是说：“嘿，我们想做这件事。我们看到你已经有了些代码片段，但我们想把它做到一个真正有影响力的规模，复现出更强的模型。我们这边有超级计算机，能提供足够的算力。”

这个帖子是公开的，任何人都能看到。我记得是 Mehdi Cherti 在上面写了第一条评论，问：“我们是一群研究人员，能提供算力，大家可以一起干。”

这条消息立刻在 Discord 上引起了反响。我很惭愧记不清所有人的网名了，但我记得当时的核心人物之一是 Clay Mullis，他后来也参与了 LAION 5B 的论文。他们说：“好啊，我们建个 Discord 服务器，把所有想复现 DALL·E 的人都拉进来，看看谁能来，谁能帮忙。”

就这样，我们作为研究者，找到了一群志同道合的人。接着，像 Richard 这样的人，还有在巴黎谷歌工作的 Romain Beaumont 也加入了。Richard 当时好像在经营自己的小公司。还有一位叫 Christoph Schumann 的德国高中老师，他也被这些技术进展深深震撼，希望能让普通人也能自由地使用这些模型。他更关注数据，觉得没有数据一切都是空谈，于是就想办法组织志愿者来一起收集数据。

所以你看，世界就是这么奇妙：不同的力量汇聚到了一起。我们这边强在模型训练，知道怎么操作超级计算机，怎么做几百上千个 GPU 的分布式训练。而另一边，则是一群以数据为中心的人，开始着手收集数据。

然后，一个非常幸运的转折点出现了。当时在学界已经很有声望的研究员，路德维希·施密特（Ludwig Schmidt），注意到了我们的努力。他带着华盛顿大学和艾伦人工智能研究所的强大团队加入了进来。恰好，他们当时已经实现了一个版本的 OpenCLIP，正在小规模地做实验，结果看起来很有趣。当然，所有人都明白，要想研究真正有意思的现象，规模必须做大。

于是，我们的目标就从复现 DALL·E，转向了 OpenCLIP。因为 OpenCLIP 的代码库已经有了，想研究它的人也都在，更重要的是，CLIP 这类模型的评估体系更成熟。如果你训练出了一个模型，你可以很方便地拿它和 OpenAI 的原始 CLIP 对比，在公开的基准上跑分，看看效果如何。但对于 DALL·E 这样的生成模型，评估标准（比如 FID）要复杂得多，很难直观地比较你的成果到底好不好。

我们认为 CLIP 是一条更好的路，因为它是一种表征学习模型，可以用于图像分类、检索等各种下游任务，而 DALL·E 只是生成一些漂亮的图片，没法作为“模型骨干”被用到其他地方。所以我们最终决定主攻 CLIP。路德维希·施密特加入了，志愿者们在收集数据，我们的超级计算机也准备就绪——所有这些因素汇集到一起，项目就真正起飞了。

这直接促成了 LAION-400M 和 LAION-5B 这两个大规模、完全开放的图文数据集的发布。我们还得到了高斯超级计算中心（Gauss Center for Supercomputing）的支持，他们为我们提供了宝贵的计算时间。虽然算力不能说完全充足，但足以让我们完成这个实验。从那时起，OpenCLIP 就成了一个被社区大量复用的模型。

回头来看，研究成果本身固然重要，但我觉得，那个“希望时刻”的意义或许更大。突然之间，所有人都明白了：是的，只要社区里有能力的成员能团结起来，汇集必要的资源，我们完全有可能追赶上像 OpenAI 那样的顶尖实验室。

因为我们用这些开放资源训练出的模型，在很多下游任务的基准测试上，表现和 OpenAI 的成果旗鼓相当，有些甚至更好。这让我们自己都感到非常惊讶。我们最初的目标，可能只是想复现出“算力越大、模型越好”的趋势，但我们实际上做到了和他们一样好，甚至更好，还发布了他们原始研究里没有提供的扩展定律。

你看，这里有个很有意思的细节：即便是我们几年前发布的那个 OpenCLIP B32 模型（在 LAION-2B 数据集的 340 亿样本上训练），到现在每个月仍然有一百多万的下载量。这说明，如果你用正确的方式做事，成果就能产生持久的影响力，对社区持续有用，而不是昙花一现。

## 从神经科学到“苦涩的教训”

**Eric Wang: 让我们把时钟拨回去一些。在“基础模型”这个词流行起来之前，是什么最初吸引您进入神经科学领域，特别是视觉皮层中的无监督学习？**

**Jenia Jitsev**: 我当时对“学习”这个抽象的过程本身非常着迷。我就在想，外界的信息就像漂浮在空中，一个系统要怎么才能捕捉它们，并把它们“刻印”在自己内部？这个过程到底是怎么运作的？这让我非常困惑。

大脑无疑是这方面的高手。我之所以对神经科学感兴趣，就是因为大脑是一个活生生的、已经成功实现了学习的系统。我当时的研究方向，就是理解大脑神经回路里的学习机制和可塑性是如何相互配合的。

但在某个阶段我意识到，如果能把这个问题再往上抽象一层，进入核心的机器学习领域，剥离掉生物学那些错综复杂的细节，或许能取得更快的进展。生物系统太复杂了，一部分复杂性可能跟信息处理有关，但另一大部分可能只是为了维持生命体征，和学习关系不大。要把这些东西完全理清楚，需要极长的时间，我感觉凭我一己之力很难搞定。所以，我选择了一条更简洁的路，尝试在更纯粹、更抽象的层面上理解学习。

后来，整个领域都发生了变化。我们当时研究的一些相当简单的方法，比如所谓的“赢者通吃”式电路（Winner-take-all-like circuits），人们发现只要把它们层层叠加、不断扩大规模，就能产生强大的学习系统。我也很自然地转向了深度学习，这个方向正是在我博士快毕业、思考未来的时候兴起的。

那段时间，我仍然做了一些偏生物学的研究，比如大脑基底节里由多巴胺调节的、基于奖励的学习机制。但与此同时，我的重心越来越偏向经典的计算机视觉和机器学习，最终来到了于利希超级计算中心。这里有大型计算机，为我提供了绝佳的“土壤”，让我能用更大规模的数据集，去“喂养”那些结构更简单但规模远超以往的网络。这很自然地，就把我引向了“基础模型”这个新兴领域，我把它们看作是“可迁移学习”的最终产物。

我一直以来的核心兴趣点从未改变：要实现真正意义上的“学习”——那种能够迁移到各种不同场景和任务中的学习——到底需要什么条件？基础模型，是第一批向我们展示了这条路该如何走的产物。所以，我开始一头扎进去，试图弄清楚它们为什么能成功，它们依然存在哪些重大的开放性问题和弱点，以及它们的泛化能力究竟能达到什么程度——因为我们已经看到，它们的泛化能力，远没有我们想象中那么强大。

**Eric Wang: 您在 GOSIM 的演讲中提到了一个分水岭：2012 年之前，整个行业都依赖标记数据，而之后，可扩展和可迁移学习取得了巨大突破。在您看来，促成这种转变的根本观念是什么？**

**Jenia Jitsev**: 我想，一个最重要的观念转变，是人们终于意识到，数据集的构成方式，对学习的成败起着决定性的作用。以前，大家更关注算法本身，觉得好的算法才是一切的关键，“以数据为中心”这个理念在很大程度上被忽略了。

一个明确的变化是，大家开始明白，要构建一个好的数据集，就必须让它的数据分布尽可能通用，并且在收集时，要尽可能少地加入人为的先验知识和偏好。于是，“网络规模”的数据集应运而生。你只需要尽可能多地从网上抓取数据，数据本身的多样性就足够了，你根本不需要过多地去预设什么是“好”数据。因为事后证明，人类在判断什么样的数据对算法（甚至是对人类自己）学习有益或有害这方面，其实做得很糟糕。

在算法层面，也发生了类似的变化。人们开始理解，算法的“可扩展性”和“通用性”才是王道。这很像强化学习之父理查德·萨顿提出的“苦涩的教训”（The Bitter Lesson）的精神：如果你能让一个程序，在“投入的计算资源越多，效果就越好”这个维度上持续扩展，那你就走在正确的路上了。 

你不需要为解决某个特定问题去费尽心思地设计精巧的规则，而是应该去思考最通用的学习范式，让它能处理任何你投喂给它的数据。

大家也明白了“简单”的重要性——但实现这种简单，本身却很难。最终胜出的，并非最简单的东西，而是那个最具有可扩展性的、简单的东西。你必须同时追求数据集和算法两方面的可扩展性。你会发现，即使是像多层感知器（MLP）这样简单的结构，它也是可扩展的。但如果你去推导它的扩展定律，就会发现它的扩展效率远不如 Transformer 架构。

Transformer 本身仍然是一个相对简单的架构，但它就是比 MLP 更具可扩展性。你必须找到这种精妙的平衡点：既要保持核心机制的简单，又要让它具备极强的可扩展性和通用性。正是数据集和算法层面上的这两个关键转变，才让我们能够创造出今天这些在可迁移学习上如此成功的模型。

## 大公司病

**Eric Wang: 现在，关于基础模型的研究似乎只有少数几家大型的工业实验室才能复现。这种现状，是 LAION 成立最主要的催化剂吗？还是说，你们也希望解决其他一些科学层面的困境？**

**Jenia Jitsev**: 即使你暂时抛开“黑箱”研究这个问题，单纯地问自己：作为一个机器学习研究者，要在这个领域探索最重要的方向，到底需要什么？你很自然就会得出结论：你需要开放的数据，这样别人才能在你工作的基础上继续构建，或者重复你的实验；你还需要开源的训练代码。

这实际上是回归了最标准的科学方法。如果我们想研究一个领域里最重要的现象——而“可迁移学习”以及作为其产物的“基础模型”，无疑是当下最重要的现象之一——那么相关的工具和材料就必须对所有人开放。只有这样，我们才能更快地取得进展，并且是以一种经过反复验证的方式，而不是像现在这样，某个公司发布一个模型，冒出来一些神奇的说法，但谁也无法验证真伪，只能花上一年半载的时间，靠着各种流言蜚语和坊间
传闻去猜测真相。

所以，对我们这些来自研究领域的人来说，最主要的催化剂，就是创造一个能进行真正科学研究的环境。我想，其他更多来自产业界的朋友，他们更担心的可能是另一件事：如果只有少数几家公司垄断了这些关键的“构建模块”，那行业的其他所有参与者，就只能被动地等待那一两个巨头下一次发布点什么，然后眼巴巴地用别人给的东西，甚至连这东西是怎么来的都不知道。

对他们来说，消除这种产业格局中的权力集中，是更紧迫的议题。我认为 LAION 在这方面也确实起到了作用。但对我们研究人员而言，动机非常纯粹：我们必须以可复现的方式来研究事物。既然它现在不可复现，那我们就亲手让它变得可复现。

当然，我们也非常感谢那些封闭的实验室——OpenAI、DeepMind、Meta、Anthropic——因为它们无疑为整个领域指明了重要的方向。做研究就是这样，你看到一些线索，就应该顺着去探索。但到了某个阶段，我们必须确保这些研究对于开放的学术界是可复现的，这正是我们投入大量努力的地方。

**Eric Wang:** LAION、EleutherAI 和 BigScience 都是非常有名的草根研究社区。您有没有想过，如果当初选择进入封闭的实验室，研究大规模模型，您的人生轨迹会有什么不同？另外，在更广泛的开源生态中，LAION 的独特之处是什么？我看你们的网站上写着“100%非营利，100%免费”。

**Jenia Jitsev**: 首先要强调，这个领域存在多样性是件好事，封闭实验室也贡献了巨大的力量。对我个人而言，选择走开源这条路，是一个非常务实，甚至可以说有点“自私”的决定。我完全不排斥去封闭实验室工作，拿高薪，有充足的资金。但我的长期感觉是，如果你以一种更开放、更协作的方式做研究，你能更容易地接触到全世界的顶尖人才，借鉴他们的智慧和技能。

当然，OpenAI、DeepMind 这些公司也汇集了世界上最顶尖的研究者，对吧？但问题在于，一旦你身处一个商业实体中，你就必须对投资者负责，他们会问你：“你的下一个利润增长点是什么？”

于是，研究方向就不可避免地会向那些更容易向投资者汇报成果的方向倾斜。这对于基础研究来说，可能是一个大问题。你可能会因为要满足一些紧迫的商业需求，而被迫忽略掉一些非常有趣、但短期内看不到商业价值的研究方向。OpenAI 的情况可能特殊一些，作为非营利组织，他们或许能摆脱一些这种压力，也确实有过为了追求重要的研究而长期亏损的阶段。但即便如此，当你开始和像微软这样有巨大影响力的大公司合作时，你同样会感受到压力，让你无法去探索那些你认为当下最有价值的方向。

所以，我再强调一下，我所说的“自私”是指：我个人认为，有些在研究层面最值得探索的方向，与商业化路径并不那么兼容。

如果我知道怎么让它们完美兼容，我完全不介意去封闭实验室工作。但我看到的现实是，开源的模式，能以一种更高效的方式，来推动那些真正重要的研究方向。也许短期来看，在封闭实验室里，你可以用更猛烈的炮火集中推进。但我相信，从中长期来看，一个拥有海量顶尖人才的、更广泛的社区，会在研究效率上获得更大的动力。这本质上是一个效率问题。当然，也许我是错的。

**Eric Wang: 您演讲中用了大约10页的篇幅来谈扩展定律，以及如何用 LAION-400M、LAION-2B 和 OpenCLIP 来实现可复现的扩展定律。在实践中，要做到“可复现”，最大的挑战是什么？这又如何体现了开放数据和模型的力量？**

**Jenia Jitsev**: 一个最明确的挑战，就是数据集的构建本身。这里面的问题太多了，短时间根本说不完。仅仅是从头开始整个流程——访问 Common Crawl，从中提取有用的元数据，再通过层层筛选来保证质量——就已经非常困难了。然后你还得真正去把图片下载下来，这同样是一个能把人逼疯的环节。最开始，你甚至需要鼓起巨大的勇气，去投入大量精力收集一些东西，而这些东西最终很有可能因为各种原因，变成一个失败的数据集。

我想我们算是运气很好。我们最初其实预期，用我们收集的数据训练出来的模型会非常平庸，和顶尖水平差距很大。但结果比预想的好，那真是一个幸运的时刻。当然，麻烦也随之而来。因为我们的数据是开放的，所以很快就有人在里面发现了一些不该存在的非法样本。

这恰恰凸显了开放的一大优势：透明。 一旦问题被发现，你就可以说：“好的，我们来修复它。”我们后来和互联网观察基金会（IWF）以及加拿大的一个组织合作，他们提供了大量不良数据的哈希列表。这对我来说是个很大的触动：原来公共互联网上还有这么多不良内容没有被服务商移除，这很奇怪，因为他们按理说是被要求这么做的。利用这些哈希值，我们才得以发布了 LAION 数据集的修复版本。

总而言之，要让扩展定律可复现，光是在数据集上，就要投入巨大的工作量。我认为这需要更多人团结起来，因为让单个组织独自承担所有这些工作，是不健康的。
当然还有其他挑战。你需要非常熟悉超级计算机的操作，需要懂得如何设计科学的实验，来获得足够好的测量数据，从而绘制图表、拟合有意义的曲线，并准确预测模型在更大规模下的表现。这纯粹是科学专业知识，我们也必须从头学起。还有计算时间本身，以及申请这些资源所要付出的努力。你需要定期写项目申请去争取算力，这也是一个相当繁琐的过程。所以说，可复现性的成本是相当高的。

我认为很重要的一点是，开源社区内部应该加强交流，探讨如何让这些流程变得更容易。比如，大家可以联合申请经费，有经验的人可以分享计算时间，互相帮一把。这样，这些繁琐的流程才不至于把我们这样小规模的非营利组织给“压垮”。要实现可复现性，你必须同时应对技术、组织和科学这三个层面的挑战。我希望我们正在这三方面不断学习和进步，让所有参与者在做这类研究时，过程能不那么痛苦。

## “爱丽丝梦游仙境”：当顶尖模型跌入逻辑的兔子洞

**Eric Wang**: “爱丽丝梦游仙境”（AIW）研究，是您演讲中非常吸引人的一部分。您是合著者之一，而这篇论文的主要作者 Mariana 和另一位合著者 Mehdi 今天也来到了 GOSIM 大会现场。

在深入探讨这篇精彩的论文之前，我个人很好奇一件事——是谁给它起了这么一个富有想象力的名字？

**Jenia Jitsev**: 哦，是的，其实是我起的。当时看到实验结果时我非常惊讶，在我看来，这些顶尖模型在处理如此简单的问题时所表现出的行为，真的像创造了一个光怪陆离、非常诡异的环境。“爱丽丝”这个名字，其实有点偶然，因为在计算机科学里，我们讨论通信问题时，经常用“爱丽丝”和“鲍勃”作为代号。
但一旦用了“爱丽丝”，就很容易让人产生联想。因为我们观察到，这些声称自己拥有强大泛化能力的模型，在一些极其简单的任务上，表现得如此奇怪，这让我觉得非常怪诞。

我当时脑海里甚至浮现出原著书中的一幅插画，我想应该是《爱丽-丝镜中奇遇记》里的场景，就是那个叫 Humpty Dumpty（矮胖墩）的蛋形人。他坐在墙上，态度非常权威、自视甚高，小女孩爱丽丝向他伸出手，结果他摇摇晃晃地，最后就摔得粉碎。这个画面在我脑海里成了一个绝佳的隐喻。

虽然我平时不太喜欢我们领域里那些故弄玄虚的标题，但这次我实在忍不住，所以就用了这个名字。

**Eric Wang: 为了让不熟悉的观众能快速了解，AIW 研究的核心发现是：即便是最顶尖的大语言模型，在面对一些核心逻辑完全不变、只是调整了几个数字的简单问题时，表现会极不稳定。当您的团队意识到这些模型存在如此根本性的困难时，那个“顿悟时刻”是怎样的？**

**Jenia Jitsev:** 说实话，我们最开始也没有意识到，仅仅是改变问题模板里的变量，就能产生这么大的影响。当时社区里已经流传过一些据说能“攻破”模型的问题，比如 2023 年网上流传的那个关于“萨莉和她的兄弟们”的逻辑题。

我们的问题和那个有些关联，但又不太一样。我们一开始测试的，只是一个固定的、静态的问题。但我们发现，即使在这种最简单的情况下，像 GPT-4 这样强大的前沿模型，有时候给出的正确率也低得奇怪。我想，就是在我们不断探索，想找到底是哪种问法能让模型“翻车”的时候，我们偶然发现了这一点，然后意识到：你其实根本不需要对问题做太多改变，你只需要改变几个数字，它就崩溃了。 那一刻，确实就是我们的“顿悟时刻”。

我们发现，导致模型崩溃的，并不是问题中某个特定的、刁钻的特征，而是某种更普遍的东西。这说明，模型的泛化能力确实出了大问题。对于一个固定的、简单的逻辑模板，你填进去一组数字，它能解决；然后你换一组稍微不同的数字，它就彻底失败了。为什么它的表现会受到如此剧烈的影响，我们至今仍在努力理解。

从那以后，我们的研究路径就非常清晰了。我们生成了大量的变体，尝试了不同的问题模板，不断地替换里面的变量，结果总是看到同样一致的现象。直到后来新一代的推理模型（比如 O1、O3）出现，我们才第一次看到有模型能在处理这类问题时，表现出一定的稳定性。但如果你把问题的结构再改得稍微复杂一点——远没有到它们声称能解决的奥林匹克竞赛或研究生级别任务的难度——它们同样会很快崩溃。

在推理模型出现之前，你可以用任何市面上最强的模型，比如 Anthropic 的 Claude、GPT系列、Mistral、Cohere 的 DBRX、Command R+，它们无一例外，都会在这种简单问题上彻底“翻车”。

而这背后真正的问题在于，几乎所有这些公司，都在它们的官网上写着：“我们的模型旨在帮助您解决严肃的、现实世界中的商业问题。” 如果你看到，一个如此简单的、符合常理的逻辑变体就能让模型严重崩溃，你就应该明白，这不仅仅是“爱丽丝”这一个问题的结构有缺陷。你可以想象任何你想用AI解决的问题，你用某个模型测试了一下，发现效果很好，于是你开始信任它。然后，你可能只是对输入做了一点微小的、你认为完全合乎逻辑的修改，结果它就在你毫无察觉的情况下，给出了一个完全错误的答案。

这种情况尤其危险，特别是当你自己也不知道正确答案，纯粹指望模型帮你解决问题的时候。对于“爱丽丝”问题，我们很容易发现模型错了，因为我们自己知道答案。但对于一个你不知道答案的复杂问题，模型不仅会给出一个错误的回应，还会用一种我们称之为“虚构”（Confabulations）的方式，非常自信地为它的错误答案辩护，告诉你：“是的，我仔细检查了我的解决方案，一切都很好。”

特别是像 DBRX 和 Cohere 的模型，它们的回应方式，总能给用户一种“一切尽在掌握”的信心，但实际上可能错得离谱。这样一来，用户根本就意识不到自己被误导了。

对于传统的大语言模型来说，这绝对是一个巨大的麻烦。对于新的推理模型，我们还需要继续观察。我们仍然能看到强烈的表现波动，但情况确实比传统LLM好得多。一个好的迹象是，我们不怎么看到它们给出那种奇怪的、过度自信的错误回答了。实际上，当你看到一个推理模型开始“吃力”的时候，它的表现会开始波动，但它同时会告诉你：“哦，等等。哦不，我不确定。嗯……这个很难。” 

这说明它具备了更好的反思能力，或者说，它对自己“不知道”这件事的校准能力更强了。这让我们对“推理模型”这条路，抱有了一丝希望。

## 从“虚构”到反思：推理模型是出路，还是又一个开始？
**Eric Wang**: AIW 论文首次发表时，推理模型还没像现在这样流行。所以你们的研究实际上横跨了两个阶段：一次是在推理模型出现前，测试了像 GPT-4、Llama 3 这样的基础模型；另一次是在推理模型出现后，你们又用同样的问题去测试它们，结果发现它们虽然有所改进，但仍然表现不佳。

这真的非常令人费解。这些难以根除的缺陷，对于我们未来该走哪条路，有什么启示？

**Jenia Jitsev**: 这是一个非常好的问题。对此，一个最直接、最简单的解释可能就是：我们用来训练推理能力的数据，可能还不够多。

我们现在也在用自己的 OpenThoughts 数据集做这方面的实验，这个数据集最初只有十一万多条“推理轨迹”（reasoning traces），现在我们已经把它扩展到了一百万条。也许，只要我们持续扩大这类数据的规模，就真的能解决这个问题。可能到了某个临界点，模型就会突然涌现出稳健的泛化能力，至少对于特定复杂度的问题是这样。
举个例子，像 DeepSeek-V2-Coder 这个模型，它是在一个基础模型之上，额外用了几十万条推理样本进行微调的。这个量，也许还不足以让模型完全、稳健地建立起核心的推理能力。

但你确实看到了明显的改进，情况在变好。所以，最符合直觉的做法，就是像以前所有被证明有效的学习过程一样，直接扩大规模。你看，之前斯坦福有一个叫 LIMA 的研究，他们只用了大概 800 到 1000 条高质量的推理轨迹，在一个传统的大语言模型（Qwen-32B）上进行微调，性能就出现了巨大的飞跃。

这就让你很自然地会去想：既然少量高质量数据就能带来巨大提升，那如果我把这个数据量扩大到两百万、五百万条，会不会在某个时刻发生质变，从而彻底解决这个问题？

当然，这里面也要小心。幸运的是，现在有了像 OpenThoughts 这样的开放数据集，还有 Hugging Face 社区也在做的 Open-Mistral-v0.2 等等努力，这让验证上述猜想成为可能。我们处在一个非常有利的位置：我们可以清晰地看到后训练数据（post-training data）是什么样的。比如，我们知道 Qwen-32B 这个基础模型解决不了“爱丽丝”问题，它在这上面表现很差，而且我们可以很确定，它的预训练数据里，没有泄露过类似的问题。然后，你拿到了完全开放的、用于后训练的推理数据，把它应用上去。你同样可以检查这批数据里有没有“爱-丝”问题——没有，不存在数据泄露。那么，模型所有的性能提升，就都归功于接触了这些通用的推理轨迹。

所以，我认为，在我们去探索更复杂的解决方案之前，首先必须把这条最直接的路验证清楚。当然，你可以想到很多种修复这个问题的方法。但是，扩大推理数据的规模——这件事现在是完全可行的，因为现在的推理模型已经足够好，可以用来生成海量的、合成的推理轨迹数据，你甚至不太需要费力地去挖掘真实数据了。

让我们先尝试把这件事做到极致，看看单靠扩大数据规模，是否足以让那些奇怪的性能波动消失。如果可以，那我们就再次证明了，这归根结底还是一个数据问题。那就太酷了。

## 展望：开放社区的未来与挑战

**Eric Wang: 随着 GOSIM 巴黎 AI 大会的进行，您对这次大会以及在这里建立的联系有什么特别的期望吗？另外，您希望明年的 GOSIM 欧洲大会在哪里举办？**

**Jenia Jitsev**: 这几个问题都很好，让我想想。在这次大会上，我见到了来自 Eclipse 基金会和 Linux 基金会的朋友，我们和 Linux 基金会一直有很好的联系。

我希望，未来我们能建立一个更有组织性的框架，来更好地发掘开源社区里这些轮流涌现的优秀人才的潜力。我希望能和这些大型开源基金会更紧密地合作，互相帮助。这次 GOSIM 大会提供了一个非常好的机会，让我们能和他们面对面地交流。
至于 GOSIM 欧洲站的举办地……我必须说，巴黎其实是最好的选择。

**Eric Wang**: 德国呢？你的故乡。

**Jenia Jitsev**: 德国处境艰难。我们必须公平地看待这一点。德国在机器学习的研究和产业方面都存在断层。我们必须修复它。法国做得好得多。但 LAION 在那里。黑森林实验室（Black Forest Labs）是德国的一大希望，他们有非常强大、非常有能力的人。但我们需要在德国把政策搞对，这样这些有能力的人才能有好的发展条件。

如果 GOSIM 要来德国，我当然有偏向。科隆会是一个不错的大城市，一个充满欢乐的城市，一方面为人们提供了很多四处走走的机会。另一方面，我们的超级计算中心就在附近。德国其他地方的人也很容易来到科隆，因为它是一个交通非常便利的枢纽。
另一个显而易见的选择是柏林。但老实说，柏林的机器学习圈子有点在衰落。我不知道为什么，这对我来说也是个谜。但我猜想，像科隆这样的聚会中心会是个不错的选择。我想很多人都能去那里，因为它很容易到达，也是一个值得参观的有趣地方。

**Eric Wang: 好的。非常感谢您，Jenia，感谢您带来的深刻见解和启发。希望我们的观众觉得有所收获。对于想更多了解您的工作或与您联系的观众，通过哪些渠道找到您最好？**

**Jenia Jitsev**: 我们当然比较多地使用 Discord。很多开源社区都在 Discord 上活动。不管是什么原因，这都有点偶然。可以来 LAION 的 Discord 服务器，我的 Discord ID 和我的名字一样。你可以随时在那里@我。也可以交换电子邮件；我 Forschungszentrum Jülich（于利希研究中心）的官方工作邮箱也是一个联系我的好地址。LinkedIn 我其实用得不多，很多 LinkedIn 上的消息我可能一个月后才看到——或者是来参加像 NeurIPS、ICLR、ICML、CVPR 这样的顶级会议。我们都会去那里，在那里交流。这也是一个好机会。

**Eric Wang:** 谢谢您，Jenia。请继续关注 GOSIM 的官方 X 和 YouTube 频道，以及 OpenAGI 论坛，获取更多精彩内容和更新。谢谢您，Jenia。非常感谢。

**Jenia Jitsev**: 谢谢。

欢迎大家持续关注 GOSIM 在 X、YouTube、Bilibili 等平台的官方账号，获取前沿的 AI 研究动态与精彩对话。

