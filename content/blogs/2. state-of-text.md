---
title: "SoRUI #1 - The State of Rust Text Rendering 2024"
date: 11 Aug 2024
description: ' '
tags: ['rust', 'ui', 'text', 'fonts']
published: false
---

This post is the first in a new series of "State of Rust UI" (SoRUI) blog posts. Each post in the series focusses on a different theme with Rust UI. The theme of this post is text rendering.

<small>Readers of this article may also be interested in this [State of Text Rendering 2024](https://behdad.org/text2024/) article by Behdad Esfahbod (HarfBuzz maintainer) which covers recent developments in text rendering more widely but has less detail about the state of the Rust ecosystem specifically.</small>

## Purpose

- Explain requirements for a text-rendering stack
- Evaluate state of rust ecosystem against those requirements
- Make recommendations of libraries to use

## Introduction

A complete solution for handling text is surprisingly complex. Although perhaps this should not be so surprising when we consider that a text rendering solution in 2024 is expected to handle every writing system in common usage: Latin, Greek, Arabic, Chinese, Japanese, Korean, Devangari, etc. And furthermore to seamlessly handle arbitrary *mixtures* of those scripts (along with extras like emoji) in the same sentence.

## Understanding The Modern Text Rendering Pipeline

A modern text rendering pipeline involves roughly the following steps:

* **Font Parsing** Parsing of font formats. Most fonts use the OpenType format. However, OpenType is really a meta/container format that may contain several different "tables" (which may contain arbitrary binary data), each identified by a 4-byte tag. In order to fully support a modern text stack you need to be able to parse the traditional tables representing TrueType font data, hinting and ligatures, tables representing Apple's AAT fonts (and their different hinting format), and several emoji formats (at least COLRv0, COLRv1, sbix, and CBDT/CBLC). You may also need to be able to decode compressed variants of OpenType fonts (WOFF and WOFF2 fonts).
* **Font enumeration** is listing (enumerating) all the fonts installed on the system. And collecting metadata about those fonts, for example whether they are serif, sans-serif, monospace, their weight, the code points they cover, etc. Such libraries will typically also load the full font into memory as required (often using mmap).
* **Font fallback** is matching runs of text to a font. This is necessary because fonts typically don't cover the entire unicode range: you have different fonts for latin text, chinese text, arabic text, etc and also usually a separate font for emoji. But if you have say arabic text or emoji embedded within latin text you don't typically specify the font for the arabic text or the emoji, one is chosen for you. That process is font fallback.
* **Clustering** is the combining unicode code points into "shaping clusters" in preparation for shaping. [Shaping clusters](https://harfbuzz.github.io/clusters.html) are distinct from [Grapheme Clusters](https://www.unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries) and are generally (always?) made up of 1 or more grapheme clusters. Clustering and font-fallback are often closely coupled with shaping in current implementations (e.g. Harfbuzz), but future implementations may be able to decouple them.
* **Shaping**, which is the process of mapping runs of unicode codepoints within shaping clusters to specific glyphs within fonts, and positioning them relative to each other. This includes simple mappings like mapping the "a" character to the appropriate "a" glyph, but also involves things like applying ligatures and resolving emoji modifiers. Some scripts (notably some Indic scripts) require much more complex transformations that involve reordering characters within a cluster.
* **Layout** is computing x/y coordinates for each glyph in a string of text. This includes things like determining a glyph's size (and the appropriate offset for that glyph relative to the previous glyph), line breaking, and [bidi](https://en.wikipedia.org/wiki/Bidirectional_text) reordering. It can also includes more advanced capabilities such as mixed media layout (placing images or other boxes inline with text), laying out around excluded areas, floated boxes. And even things like following an arbitrary vector path.
* **Scaling** is taking the vector outlines of a glyph from the font file and scaling them to the correct size according to the font size being used. These outlines are often then further adjusted by a **Hinting** algorithm that applies fine tweaks.
* **Rasterisation** converts the scaled and hinted vector outlines into a raster bitmap of pixels. Scaling and hinting are sometimes treated as part of "rasterisation" but in this article we will treat these as separate processes. As this process is relatively computationally expensive and is repeated many times (for the same glyph, both within a scene and accross frames), efficient rasterisation can also involve a system for caching the rasterised glyphs.

While not strictly part of *rendering* text. Most text systems will also require:

* **Text Selection** is the ability to mark text as selected. Text should generally be selectable by clicking and dragging the mouse, by using various standard keyboard shortcuts, and via accessibility APIs.
* **Text Input/Editing** is the ability for the user to manipulate text. This requires responding to keyboard input and ensuring that the text is altered appropriately. It also requires interacting with system Input Methods (IMEs). Similar to layout, advanced text editing controls may need to deal with editing rich text and/or mixed media.

Bonus: subsetting

## Platform Text Stacks

One approach to dealing with the complexity of text handling is to use the platform's built-in libraries: DirectWrite on windows, CoreText on macOS/iOS, and Harfbuzz+Freetype on Linux/Android.

**Advantages of this approach are:**

- Text is rendered such that it exactly matches the way that "actually native" applications that use the system UI toolkit(s) for that platform (Win32/WPF/AppKit/SwiftUI/etc)
- It can reduce binary size (as text rendering code is dynamically linked from the OS and doesn't have to be included in your app)

**Disadvantages of using system APIs include:**

- You have to implement everything multiple times (once per platform) as each platform has a different API.
- You can end up with text rendering that varies subtly between platforms.
- If you only use system APis then you are limited to the lowest-common denominator of functionally that all platforms which you run on support.
- It can be quite difficult to mix-and-match use of system APIs with custom code (for example, to implement a layout feature that some platform APIs don't support) as they are typically not designed for this use case.

**Notable cross-platform applications/frameworks which do this include:**

- React-Native uses the full system text stack on all platforms.
- Browsers (Chrome, Firefox, Servo) take a hybrid approach: using Harfbuzz for shaping on all platforms, doing their own font-fallback and layout, but using the system libraries for rasterization (polyfilling unsupported formats where necessary).

**However a big downside of this approach in Rust is that there is no high-level library implementing such a strategy available**



TODO: is it possible to use system rasterization without shaping? (yes: browsers do this. But doesn't always support things like COLR).
TODO: Limitation around font loading with system rasterisation (only applies to CoreText?)


### Unicode text handling

Rust, being a new language, is at an advantage in that it's standard library types (such as `String`) represent text as UTF-8. So basic text storage and processing is covered.

However, there are a number of more specific unicode handling routines and algorithms (normalization, segmentation, etc) that are not included in `std` that require an external library. There are two main sets of crates for this in the Rust ecosystem:

- The `unicode-*` crates. These were some of the earlier unicode handling crates in Rust and are widely used.
- The `icu4x` crates. These are a official Unicode Consortium project.

There is also `xi-unicode`, but it is effectively in maintenance mode, with the linebender organization who created it looking to move to the `icu4x` crates.

In general the `icu4x` crates are more correct/complete, but the `unicode-*` crates are still pretty good and may be faster / more lightweight. For example, the `icu_segmentation` crate offers dictionary-based word segmentation for the Thai language (which doesn't separate words using spaces) which is important for segmenting Thai but comes at the cost of including the dictionary data. It also offers customizations for different CSS line-breaking modes. Whereas `unicode-segmentation` doesn't offer either of these options but does otherwise correctly implement the unicode segmentation algorithms.

I would suggest defaulting to the icu crates. 

### Font Parsing

If you are using higher-level text libraries then you may not have much choice in which low-level parsing library is used as the higher-level libraries are generally coupled to a specific parsing library. However, you may need to pick one if you are interacting with fonts at a low level.

Knowing about the low-level parsing libraries may be useful when evaluating which set of high-level libraries to use. In particular, you may wish to pick a set of libraries that all depend on the same low-level libraries to avoid bloating your build times and binary size.

The C libraries Freetype and and Harfbuzz both have comprehensive support for parsing OpenType fonts, and these are definitely viable options for font parsing in Rust, with high quality bindings maintained by the Servo project available ([rust-harfbuzz](https://github.com/servo/rust-harfbuzz) and [rust-freetype](https://github.com/servo/rust-freetype)). However they have all of the usual disadvantages of C libraries including the possibility of memory vulnerabilities and unergonomic APIs, and with high-quality pure-rust options available there is little reason to use them unless you are need some of their other capabilities.

The pure-rust parsing libraries are:

- [ttf-parser](https://github.com/RazrFalcon/ttf-parser) is a mature, performant, hand-written parser that has excellent support for the majority of OpenType tables including emoji tables such as CAPL/COLR and sbix, and variable font tables like AVAR (TODO: check tables). 
- read-fonts/skrifa is a new project which uses code generation to generate the parsing code for each table. It also has wide

([Swash](https://github.com/dfrg/swash) also has it's own font parsing code. But this part of Swash has been deprecated in favour of read-fonts/skrifa so it can be discounted for new projects)


TODO:comparison used LaurenzV's writeup.
https://github.com/googlefonts/fontations/issues/956#issuecomment-2226327930
- Both libraries are excellent with little technically separate them at this point.
- Skrifa more equiv to ttf_parser than just read-fonts
- ttf_parser has better table coverage (AAT), but Skrifa rapidly catching up
- Skrifa has more development momentum (inclusion into Chrome + associated maintenance)
- Fontations also has write-fonts.

**Recommendation:** ttf_parser or read-fonts+skrifa depending on which the higher-level libraries you want to use depend on.

TODO: System libs?


### Font Databases: Enumeration, Loading & Querying

There are 3 main crates which do font enumeration in the Rust ecosystem:

- font-kit
- fontdb
- fontique

Font-kit is different from the other two in that it allows fonts to be loaded as handles to the system libraries' (DirectWrite, CoreText and Freetype) native font representations.

Both `fontdb` and `fontique` have standardised on `Arc<dyn AsRef<[u8]> + Send + Sync>` as the underlying type for raw font data. Which (in both cases) is backed by either a memory mapped file (for system fonts) or a `Vec<u8>` if in-memory font data is loaded by the user. And more than any other part of the ecosystem these libraries are excellent candidates for a merging of projects.

The main differences between the two libraries are:

The font enumeration methods:

- Fontdb uses simple filesystem scanning with hardcoded directories. This has the advantage of being simple and lightweight, but the disadvantage of being incompatible with what other applications on a user's system do which can lead to fonts not being picked up. 
- Fontique hooks into the system-provided mechanisms for enumeration, falling back to scanning where these are inadequate or not available. This has the advantage of matching system norms at the cost of having to depend on relatively heavy system libraries.

And the underlying font parsing library:

- Fontdb uses `ttf_parser`.
- Fontique uses `read_fonts`+`skrifa`

However, it should be relatively easy to merge the enumeration methods by implementing a superset and making use of feature-flagging to allow end-users to make their own trade-offs regarding dependency weight and enumeration fidelity.

Regarding the font parsing library, ideally there should only be one. However, neither library's use of font parsing is that widespread, so it came to it then this could also be abstracted into feature-flagged backends.

The motivation for enacting a merge is interoperability. Many text/font-related activities can be performed independently (so it would be relatively easy for the ecosystem to support multiple options that could be mixed and matches). However, they almost all require a database of fonts and that database really ought to be a global resource that is only loaded once to keep memory usage low. And a single, agreed-upon font database library would make interoperability between the various libraries much smoother.

### Clustering, Shaping & Fallback

- Harfbuzz
- Rustybuzz
- Harfruzz
- Swash
- Allsorts

### Layout, Selection & Editing

- Cosmic-Text
- Parley
- (+ something (winit?) for IME)

### Scaling & Hinting

There are only two pure-rust solutions for scaling/hinting: Swash and Skrifa.

From a technical perspective, Swash is currently slightly more complete with Skrifa not supporting as many emoji formats. Swash also includes (optional) built-in rasterisation. However, Skrifa is actively implementing the missing emoji formats, integrating it with a rasterizer is not hard (and may well be something you need to do anyway if you don't want to use Swash's rasterizer), the scaling part of Skrifa is more correct and better tested code, and the Skrifa has much better hinting support (including freetype-compatible autohinting).

But perhaps the more important factor in choosing between the two is that Swash is in maintenance with all further development effort (except critical bug fixes) from it's author Chad Brokaw being put into Skrifa, which is being actively developed with funding from Google for inclusion in Chromium (and as such is all-but guaranteed to be supported long-term).

**Recommendation**: Swash in the short-term (next ~6 months) for better emoji support, otherwise Skrifa.**

Let us compare each of these options by pipeline stage:

### Rasterization

Rasterization is quite different to other pipeline stages in that there are many different viable options, and you can mostly mix-and-match them with the other parts of your text stack. This is because once you scaled and hinted the font outlines they end up being a generic vector format (or something raster format in the case of glyphs from bitmap emoji fonts).

- System libs: wr_glyph_rasterizer
- Freetype
- Swash/Zeno
- Skrifa
- Path rasterizer:
  - Tiny-Skia
  - Vello
  - Skia
  - Etc

## What should I use today?

As a high-level solution you really have 2 choices (unless you want to build your own out of components):

1. **The Cosmic Text stack**:
  - `unicode-*` crates for unicode handling
  - `ttf_parser` for font parsing
  - `fontdb` as a font-database that does font-enumeration
  - `rustybuzz` for shaping
  - `cosmic-text` for layout, selection, and editing (+font-fallback on top of `fontdb`)
  - `swash` for scaling/hinting
  - You can then mix and match any rasterizer (more on this below)
2. **The Parley stack**:
  - Currently `xi-unicode` and `swash` for unicode handling. But planning to switch to `icu4x` crates.
  - `read-fonts`+`skrifa` for font parsing
  - `fontique` as a font-database that does font-enumeration
  - `swash` for shaping
  - `parley` for layout, selection, and editing (+font-fallback on top of `fontdb`)
  - `swash` or `skrifa` for scaling/hinting
  - You can then mix and match any rasterizer (more on this below)

The key differences are:

- Cosmic-Text uses RustyBuzz for shaping and Parley uses Swash. While Swash is much faster, RustyBuzz is a clear winner here from a quality point of view, which Swash having poor support for Indic scripts. However, Parley will likely soon switch to Harfruzz, which will make this a moot point.
- Parley has better support for rich text and mixed media layout. Cosmic-Text only recently added support for paragraphs of text with mixed font sizes and still [has bugs](https://github.com/pop-os/cosmic-text/issues/290) with this feature. Parley has good support for mixed font sizes and additionally supports inline boxes for mixed media layout.
- Cosmic-Text has optimizations for lazily layouting very large documents with fixed line heights, which is useful for plain-text editing and terminal rendering use cases (which just happen to be core use cases for it's developers).
- They use different "font database" libraries in fontdb and fontique. Fontique has better support for loading system fonts and font fallback, but fontdb is better at being a "pure font database" into which you can load your own fonts. Ultimately neither are a complete solution and both need work. Both are also quite small libraries, and would be good candidates for a merging of projects.

CHECK:
There is one similarity between the stacks which is the Scaling/Hinting is 

## A vision for the future

- Agree on a font parsing library (probably skrifa/read-fonts)
- Merge fontdb and fontique (superset of functionality)
- Parley to switch to RustyBuzz/HarfRuzz
- Both stacks can move from Swash to Skrifa for scaling/hinting
- Potentially merge Cosmic-Text and Parley (or not).

